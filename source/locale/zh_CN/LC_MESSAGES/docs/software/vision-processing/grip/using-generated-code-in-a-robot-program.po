# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2019, FIRST
# This file is distributed under the same license as the FIRST Robotics
# Competition package.
# Soha Jin <soha@lohu.info>, 2019.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: FIRST Robotics Competition 2019\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2019-09-23 22:33+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.7.0\n"

#: ../../source/docs/software/vision-processing/grip/using-generated-code-in-a-robot-program.rst:2
msgid "Using Generated Code in a Robot Program"
msgstr ""

#: ../../source/docs/software/vision-processing/grip/using-generated-code-in-a-robot-program.rst:3
msgid ""
"GRIP generates a class that can be added to an FRC program that runs on a"
" roboRIO and without a lot of additional code, drive the robot based on "
"the output."
msgstr ""

#: ../../source/docs/software/vision-processing/grip/using-generated-code-in-a-robot-program.rst:6
msgid ""
"Included here is a complete sample program that uses a GRIP pipeline that"
" drives a robot towards a piece of retroreflective material."
msgstr ""

#: ../../source/docs/software/vision-processing/grip/using-generated-code-in-a-robot-program.rst:9
msgid ""
"This program is designed to illustrate how the vision code works and does"
" not necessarily represent the best technique for writing your robot "
"program. When writing your own program be aware of the following "
"considerations:"
msgstr ""

#: ../../source/docs/software/vision-processing/grip/using-generated-code-in-a-robot-program.rst:12
msgid ""
"**Using the camera output for steering the robot could be problematic**. "
"The camera code in this example that captures and processes images runs "
"at a much slower rate that is desirable for a control loop for steering "
"the robot. A better, and only slightly more complex solution, is to get "
"headings from the camera and it's processing rate, then have a much "
"faster control loop steering to those headings using a gyro sensor."
msgstr ""

#: ../../source/docs/software/vision-processing/grip/using-generated-code-in-a-robot-program.rst:16
msgid ""
"**Keep the vision code in the class that wraps the pipeline**. A better "
"way of writing object oriented code is to subclass or instantiate the "
"generated pipeline class and process the OpenCV results there rather than"
" in the robot program. In this example, the robot code extracts the "
"direction to drive by manipulating the resultant OpenCV contours. By "
"having the OpenCV code exposed throughout the robot program it makes it "
"difficult to change the vision algorithm should you have a better one."
msgstr ""

#: ../../source/docs/software/vision-processing/grip/using-generated-code-in-a-robot-program.rst:22
msgid "Iterative program definitions"
msgstr ""

#: ../../source/docs/software/vision-processing/grip/using-generated-code-in-a-robot-program.rst:52
msgid ""
"In this first part of the program you can see all the import statements "
"for the WPILib classes used for this program."
msgstr ""

#: ../../source/docs/software/vision-processing/grip/using-generated-code-in-a-robot-program.rst:54
msgid "The **image width and height** are defined as 320x240 pixels."
msgstr ""

#: ../../source/docs/software/vision-processing/grip/using-generated-code-in-a-robot-program.rst:55
msgid ""
"The **VisionThread** is a WPILib class makes it easy to do your camera "
"processing in a separate thread from the rest of the robot program."
msgstr ""

#: ../../source/docs/software/vision-processing/grip/using-generated-code-in-a-robot-program.rst:57
msgid ""
"**centerX** value will be the computed center X value of the detected "
"target."
msgstr ""

#: ../../source/docs/software/vision-processing/grip/using-generated-code-in-a-robot-program.rst:58
msgid ""
"**RobotDrive** encapsulates the 4 motors on this robot and allows "
"simplified driving."
msgstr ""

#: ../../source/docs/software/vision-processing/grip/using-generated-code-in-a-robot-program.rst:59
msgid ""
"**imgLock** is a variable to synchronize access to the data being "
"simultaneously updated with each image acquisition pass and the code "
"that's processing the coordinates and steering the robot."
msgstr ""

#: ../../source/docs/software/vision-processing/grip/using-generated-code-in-a-robot-program.rst:84
msgid ""
"The **robotInit()** method is called once when the program starts up. It "
"creates a **CameraServer** instance that begins capturing images at the "
"requested resolution (IMG_WIDTH by IMG_HEIGHT)."
msgstr ""

#: ../../source/docs/software/vision-processing/grip/using-generated-code-in-a-robot-program.rst:87
msgid ""
"Next an instance of the class **VisionThread** is created. VisionThread "
"begins capturing images from the camera asynchronously in a separate "
"thread. After processing each image, the pipeline computed **bounding "
"box** around the target is retrieved and it's **center X** value is "
"computed. This centerX value will be the x pixel value of the center of "
"the rectangle in the image."
msgstr ""

#: ../../source/docs/software/vision-processing/grip/using-generated-code-in-a-robot-program.rst:91
msgid ""
"The VisionThread also takes a **VisionPipeline** instance (here, we have "
"a subclass **MyVisionPipeline** generated by GRIP) as well as a callback "
"that we use to handle the output of the pipeline. In this example, the "
"pipeline outputs a list of contours (outlines of areas in an image) that "
"mark goals or targets of some kind. The callback finds the bounding box "
"of the first contour in order to find its center, then saves that value "
"in the variable centerX. Note the synchronized block around the "
"assignment: this makes sure the main robot thread will always have the "
"most up-to-date value of the variable, as long as it also uses "
"**synchronized** blocks to read the variable."
msgstr ""

#: ../../source/docs/software/vision-processing/grip/using-generated-code-in-a-robot-program.rst:112
msgid ""
"This, the final part of the program, is called repeatedly during the "
"**autonomous period** of the match. It gets the **centerX** pixel value "
"of the target and **subtracts half the image width** to change it to a "
"value that is **zero when the rectangle is centered** in the image and "
"**positive or negative when the target center is on the left or right "
"side of the frame.** That value is used to steer the robot towards the "
"target."
msgstr ""

#: ../../source/docs/software/vision-processing/grip/using-generated-code-in-a-robot-program.rst:117
msgid ""
"Note the **synchronized** block at the beginning. This takes a snapshot "
"of the most recent centerX value found by the VisionThread."
msgstr ""

