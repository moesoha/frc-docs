# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2019, FIRST
# This file is distributed under the same license as the FIRST Robotics
# Competition package.
# Soha Jin <soha@lohu.info>, 2019.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: FIRST Robotics Competition 2019\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2019-09-23 22:33+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.7.0\n"

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:2
msgid "2017 Vision Examples"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:5
msgid "LabVIEW"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:7
msgid ""
"The 2017 LabVIEW Vision Example is included with the other LabVIEW "
"examples. From the Splash screen, click Support->Find FRC Examples or "
"from any other LabVIEW window, click Help->Find Examples and locate the "
"Vision folder to find the 2017 Vision Example. The example images are "
"bundled with the example."
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:10
msgid "C++/Java"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:12
msgid ""
"We have provided a GRIP project and the description below, as well as the"
" example images, bundled into a ZIP that `can be found on TeamForge "
"<https://usfirst.collab.net/sf/frs/do/viewRelease/projects.wpilib/frs.sample_programs.2017_c_java_vision_sample>`_."
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:14
msgid ""
"See :ref:`docs/software/vision-processing/grip/using-generated-code-in-a"
"-robot-program:Using Generated Code in a Robot Program` for details about"
" integrating GRIP generated code in your robot program."
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:16
msgid ""
"The code generated by the included GRIP project will find OpenCV contours"
" for green particles in images like the ones included in the Vision "
"Images folder of this ZIP. From there you may wish to further process "
"these contours to assess if they are the target. To do this:"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:18
msgid ""
"Use the boundingRect method to draw bounding rectangles around the "
"contours"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:19
msgid ""
"The LabVIEW example code calculates 5 separate ratios for the target. "
"Each of these ratios should nominally equal 1.0. To do this, it sorts the"
" contours by size, then starting with the largest, calculates these "
"values for every possible pair of contours that may be the target, and "
"stops if it finds a target or returns the best pair it found."
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:21
msgid ""
"In the formulas below, each letter refers to a coordinate of the bounding"
" rect (H = Height, L = Left, T = Top, B = Bottom, W = Width) and the "
"numeric subscript refers to the contour number (1 is the largest contour,"
" 2 is the second largest, etc)."
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:23
#, python-format
msgid "Top height should be 40% of total height (4 in / 10 in):"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:25
msgid "\\textit{Group Height} = \\frac{H_1}{0.4 (B_2 - T_1)}"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:27
#, python-format
msgid ""
"Top of bottom stripe to top of top stripe should be 60% of total height "
"(6 in / 10 in):"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:29
msgid "\\textit{dTop} = \\frac{T_2 - T_1}{0.6 (B_2 - T_1)}"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:31
msgid ""
"The distance between the left edge of contour 1 and the left edge of "
"contour 2 should be small relative to the width of the 1st contour; then "
"we add 1 to make the ratio centered on 1:"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:33
msgid "\\textit{LEdge} = \\frac{L_1 - L_2}{W_1} + 1"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:35
msgid "The widths of both contours should be about the same:"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:37
msgid "\\textit{Width ratio} = \\frac{W_1}{W_2}"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:39
msgid "The larger stripe should be twice as tall as the smaller one"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:41
msgid "\\textit{Height ratio} = \\frac{H_1}{2 H_2}"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:43
msgid "Each of these ratios is then turned into a 0-100 score by calculating:"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:45
msgid "100 - (100 \\cdot \\mathrm{abs}(1 - \\textit{Val}))"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:47
msgid ""
"To determine distance, measure pixels from top of top bounding box to "
"bottom of bottom bounding box:"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:49
msgid ""
"\\textit{distance} = \\frac{\\textit{Target height in ft.} (10/12) \\cdot"
" \\textit{YRes}}{2 \\cdot \\textit{PixelHeight} \\cdot \\tan "
"(\\textit{viewAngle of camera})}"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:51
msgid ""
"The LabVIEW example uses height as the edges of the round target are the "
"most prone to noise in detection (as the angle points further from the "
"camera   the color looks less green). The downside of this is that the "
"pixel height of the target in the image is affected by perspective "
"distortion from the angle of the camera. Possible fixes include:"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:53
msgid "Try using width instead"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:54
msgid ""
"Empirically measure height at various distances and create a lookup table"
" or regression function"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:55
msgid ""
"Mount the camera to a servo, center the target vertically in the image "
"and use servo angle for distance calculation (you'll have to work out the"
" proper trig yourself or find a math teacher to help!)"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/2017-vision-examples.rst:56
msgid ""
"Correct for the perspective distortion using OpenCV. To do this you will "
"need to `calibrate your camera with OpenCV "
"<https://docs.opencv.org/3.4.6/d4/d94/tutorial_camera_calibration.html>`_."
" This will result in a distortion matrix and camera matrix. You will take"
" these two matrices and use them with the undistortPoints function to map"
" the points you want to measure for the distance calculation to the "
"\"correct\" coordinates (this is much less CPU intensive than "
"undistorting the whole image)"
msgstr ""

