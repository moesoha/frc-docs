# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2019, FIRST
# This file is distributed under the same license as the FIRST Robotics
# Competition package.
# Soha Jin <soha@lohu.info>, 2019.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: FIRST Robotics Competition 2019\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2019-09-23 22:33+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.7.0\n"

#: ../../source/docs/software/vision-processing/introduction/strategies-for-vision-programming.rst:4
msgid "Strategies for Vision Programming"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/strategies-for-vision-programming.rst:6
msgid ""
"Using computer vision is a great way of making your robot be responsive "
"to the elements on the field and make it much more autonomous. Often in "
"FRC games there are bonus points for autonomously shooting balls or other"
" game pieces into goals or navigating to locations on the field. Computer"
" vision is a great way of solving many of these problems. And if you have"
" autonomous code that can do the challenge, then it can be used during "
"the teleop period as well to help the human drivers."
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/strategies-for-vision-programming.rst:8
msgid ""
"There are many options for choosing the components for vision processing "
"and where the vision program should run. WPILib and associated tools "
"support a number of options and give teams a lot of flexibility to decide"
" what to do. This article will attempt to give you some insight into many"
" of the choices and tradeoffs that are available."
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/strategies-for-vision-programming.rst:13
msgid "OpenCV Computer Vision Library"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/strategies-for-vision-programming.rst:15
msgid ""
"**OpenCV** is an open source computer vision library that is widely used "
"throughout academia and industry. It has support from hardware "
"manufactures providing GPU accelerated processing, it has bindings for a "
"number of languages including C++, Java, and Python. It is also well "
"documented with many web sites, books, videos, and training courses so "
"there are lots of resources available to help learn how to use it. The "
"C++ and Java versions of WPILib include the OpenCV libraries, there is "
"support in the library for capturing, processing and viewing video, and "
"tools to help you create your vision algorithms. For more information "
"about OpenCV see https://opencv.org."
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/strategies-for-vision-programming.rst:18
msgid "Vision Code on roboRIO"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/strategies-for-vision-programming.rst:22
msgid ""
"Vision code can be embedded into the main robot program on the roboRIO. "
"Building and running the vision code is straightforward because it is "
"built and deployed along with the robot program. The vision code can be "
"written by hand or generated by GRIP in either C++ or Java. The "
"disadvantage of this approach is that having vision code running on the "
"same processor as the robot program can cause performance issues. This is"
" something you will have to evaluate depending on the requirements for "
"your robot and vision program."
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/strategies-for-vision-programming.rst:24
msgid ""
"In this approach, the vision code simply produces results that the robot "
"code directly uses. Be careful about synchronization issues when writing "
"robot code that is getting values from a vision thread. The GRIP "
"generated code and the VisionRunner class in WPILib make this easier."
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/strategies-for-vision-programming.rst:26
msgid ""
"Using functions provided by the CameraServer class, the video stream can "
"be sent to dashboards such as Shuffleboard so operators can see what the "
"camera sees. In addition, annotations can be added to the images using "
"OpenCV commands so targets or other interesting objects can be identified"
" in the dashboard view."
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/strategies-for-vision-programming.rst:29
msgid "Vision Code on DS Computer"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/strategies-for-vision-programming.rst:33
msgid ""
"When vision code is running on the DS computer, the video is streamed "
"back to the Driver Station laptop for processing. Even the older "
"Classmate laptops are substantially faster at vision processing than the "
"roboRIO. GRIP can be run on the Driver Station laptop directly with the "
"results sent back to the robot using NetworkTables. Alternatively you can"
" write your own vision program using a language of your choosing. Python "
"makes a good choice since there is a native NetworkTables implementation "
"and the OpenCV bindings are very good."
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/strategies-for-vision-programming.rst:35
msgid ""
"After the images are processed, the key values such as the target "
"position, distance or anything else you need can be sent back to the "
"robot with NetworkTables. This approach generally has higher latency, as "
"delay is added due to the images needing to be sent to the laptop. "
"Bandwidth limitations also limit the maximum resolution and FPS of the "
"images used for processing."
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/strategies-for-vision-programming.rst:37
msgid "The video stream can be displayed on Shuffleboard or in GRIP."
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/strategies-for-vision-programming.rst:40
msgid "Vision Code on Coprocessor"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/strategies-for-vision-programming.rst:44
msgid ""
"Coprocessors such as the Raspberry Pi are ideal for supporting vision "
"code (see :ref:`docs/software/vision-processing/raspberry-pi/using-the-"
"raspberry-pi-for-frc:Using the Raspberry Pi for FRC`). The advantage is "
"that they can run full speed and not interfere with the robot program. In"
" this case, the camera is probably connected to the coprocessor or (in "
"the case of Ethernet cameras) an Ethernet switch on the robot. The "
"program can be written in any language; Python is a good choice because "
"of its simple bindings to OpenCV and NetworkTables. Some teams have used "
"high performance vision coprocessors such as the Nvidia Jetson for "
"fastest speed and highest resolution, although this approach generally "
"requires advanced Linux and programming knowledge."
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/strategies-for-vision-programming.rst:46
msgid ""
"This approach takes a bit more programming expertise as well as a small "
"amount of additional weight, but otherwise it brings the best of both "
"worlds compared to the other two approaches, as coprocessors are much "
"faster than the roboRIO and the image processing can be performed with "
"minimal latency or bandwidth use."
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/strategies-for-vision-programming.rst:48
msgid ""
"Data can be sent from the vision program on the coprocessor to the robot "
"using NetworkTables or a private protocol over a network or serial "
"connection."
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/strategies-for-vision-programming.rst:51
msgid "Camera Options"
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/strategies-for-vision-programming.rst:53
msgid ""
"There are a number of camera options supported by WPILib. Cameras have a "
"number of parameters that affect operation; for example, frame rate and "
"image resolution affect the quality of the received images, but when set "
"too high impact processing time and, if sent to the driver station, may "
"exceed the available bandwidth on the field."
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/strategies-for-vision-programming.rst:55
msgid ""
"The CameraServer class in C++ and Java is used to interface with cameras "
"connected to the robot. It retrieve frames for local processing through a"
" Source object and sends the stream to your driver station for viewing or"
" processing there."
msgstr ""

#: ../../source/docs/software/vision-processing/introduction/strategies-for-vision-programming.rst:57
msgid ""
"Details on using cameras with WPILib are detailed in :doc:`using-the-"
"cameraserver-on-the-roborio`."
msgstr ""

